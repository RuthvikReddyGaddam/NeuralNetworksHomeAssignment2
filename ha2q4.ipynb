{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Implementing and Comparing CNN Architectures (30 points)\n",
    "\n",
    "1. Task 1: Implement AlexNet Architecture (15 points)\n",
    "\n",
    "Write a Python script using TensorFlow/Keras to implement a simplified AlexNet model with the following layers:\n",
    "\n",
    "        - Conv2D Layer: 96 filters, kernel size = (11,11), stride = 4, activation = ReLU\n",
    "        - MaxPooling Layer: pool size = (3,3), stride = 2\n",
    "        - Conv2D Layer: 256 filters, kernel size = (5,5), activation = ReLU\n",
    "        - MaxPooling Layer: pool size = (3,3), stride = 2\n",
    "        - Conv2D Layer: 384 filters, kernel size = (3,3), activation = ReLU\n",
    "        - Conv2D Layer: 384 filters, kernel size = (3,3), activation = ReLU\n",
    "        - Conv2D Layer: 256 filters, kernel size = (3,3), activation = ReLU\n",
    "        - MaxPooling Layer: pool size = (3,3), stride = 2\n",
    "        - Flatten Layer\n",
    "        - Fully Connected (Dense) Layer: 4096 neurons, activation = ReLU\n",
    "        - Dropout Layer: 50%\n",
    "        - Fully Connected (Dense) Layer: 4096 neurons, activation = ReLU\n",
    "        - Dropout Layer: 50%\n",
    "        - Output Layer: 10 neurons, activation = Softmax\n",
    "\n",
    "Print the model summary after defining it.\n",
    "\n",
    "Task 2: Implement a Residual Block and ResNet (15 points)\n",
    "\n",
    "2.  Write a Python script to define a Residual Block and use it to build a simple ResNet-like model.\n",
    "\n",
    "            1. Implement a function residual_block(input_tensor, filters) that:\n",
    "                    - Takes an input tensor.\n",
    "                    - Applies two Conv2D layers (each with 64 filters, kernel size = (3,3), activation = ReLU).\n",
    "                    - Includes a skip connection that adds the input tensor to the output before activation.\n",
    "\n",
    "            2. Create a ResNet model that:\n",
    "                    - Uses an initial Conv2D layer (64 filters, kernel size = (7,7), stride = 2).\n",
    "                    - Applies two residual blocks.\n",
    "                    - Ends with a Flatten layer, Dense layer (128 neurons), and Output layer (Softmax).\n",
    "\n",
    "    Print the model summary after defining it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary dependencies\n",
    "import tensorflow as tf \n",
    "import numpy as numpy\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D,  ReLU, Add, Flatten, Dense, GlobalAveragePooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the AlexNet CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(filters = 96, kernel_size = (11,11), strides = 4, activation = 'relu', input_shape = (227, 227, 3)),\n",
    "    MaxPooling2D(pool_size = (3,3), strides = 2),\n",
    "    Conv2D (filters = 256, kernel_size = (5,5), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (3,3), strides = 2),\n",
    "    Conv2D(filters = 384, kernel_size = (3,3)),\n",
    "    Conv2D(filters = 384, kernel_size = (3,3)),\n",
    "    Conv2D(filters = 256, kernel_size = (3,3)),\n",
    "    MaxPooling2D(pool_size = (3,3), strides = 2),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation =\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation = \"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ResNet model\n",
    "# Residual Block Function\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x  # Identity shortcut\n",
    "    \n",
    "    # First Conv Layer\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Second Conv Layer\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add shortcut connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Define ResNet Model\n",
    "def build_resnet():\n",
    "    inputs = Input(shape=(224, 224, 3))  # Standard input size\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Residual Blocks (2 Blocks)\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "    # Global Average Pooling & Fully Connected Layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)  # Output for 10 classes\n",
    "\n",
    "    # Create Model\n",
    "    model = Model(inputs, outputs, name=\"ResNet\")\n",
    "    return model\n",
    "\n",
    "# Build and Print Model Summary\n",
    "resnet_model = build_resnet()\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
